{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUJvZ5AB66eB"
   },
   "source": [
    "# <center>South African Language Identification</center>\n",
    "\n",
    "\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K69W77Mn7j3g"
   },
   "source": [
    "## <center>Introduction</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "\n",
    "The key deliverables in this project include:\n",
    "* Developing a model that can identify South African languages based on the dataset provided.\n",
    "* Provide a clear explanation about the performance of the model.\n",
    "* Analyse the data and generate valuable insights to inform model tuning.\n",
    "* Provide recommendations based on the performance of classification models applied to the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* 1. [Importing Packages](#Importing_Packages)\n",
    "\n",
    "* 2. [Loading Data](#Loading_Data)\n",
    "\n",
    "* 3. [Data Preproprocessing](#Data_Preprocessing)\n",
    "    \n",
    "* 4. [Feature Engineering](#Feature_Engineering)\n",
    "    * 4.1. [Tfid Vectorizer](#tfidvectorizer)\n",
    "    * 4.2. [Count Vectorizer](#countvectorizer)\n",
    "    * 4.3. [Prepare Data for Training](#preparedatafortraining)\n",
    "    \n",
    "* 5. [Modelling](#Modelling)\n",
    "    * 5.1. [Build Classification Models](#buildclassificationmodels)\n",
    "    * 5.2. [Logistic Regression](#logisticregression)\n",
    "    * 5.3. [Passive Aggressive Classifier](#passiveaggressiveclassifier)\n",
    "    * 5.4. [XGBoost Classifier](#xgboostclassifer)\n",
    "    * 5.5. [Naive Bayes](#naivebayes)\n",
    "    * 5.6. [Submission](#submission)\n",
    "    \n",
    "* 6. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL2kUM5f-iFC"
   },
   "source": [
    " \n",
    "## 1. Importing Packages <a class=\"anchor\" id=\"Importing_Packages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1648731193416,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "TwB51nKw-tkF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jack/.pyenv/versions/3.10.2/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "\n",
    "# Libraries for Data Preprocessing and Modelling\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set Plot Style\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU3okGwGBJfs"
   },
   "source": [
    "## 2. Loading Data <a class=\"anchor\" id=\"Loading_Data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxZJvaD3HmhE"
   },
   "source": [
    "The dataset is an aggregation South African official languages, which total about 11. The dataset contains:\n",
    "* lang-id: Unique String (Language Abbreviation)\n",
    "* text: Sample texts in different languages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1648731193417,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "ty2Rfu0YBQ10",
    "outputId": "df1eb970-9189-4e35-a1b0-337b54751412"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train_set.csv')\n",
    "df_test = pd.read_csv('data/test_set.csv')\n",
    "samplesubmission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# Preview Train Data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfhUl2mKJzLJ"
   },
   "source": [
    "Let us look at the bottom rows of the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1648731193418,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "tOFVHJyYJ6TN",
    "outputId": "ef766d35-70b9-4118-9501-0833893fc4c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "32997     eng  closing date for the submission of completed t...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1648731193419,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "Ql8QQNg3GNOG",
    "outputId": "604551ce-2da0-4f27-dfdf-12ba4b95164b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Test Data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UlsmI4kGZCD"
   },
   "source": [
    "Check the shapes of the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1648731193420,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "qlsAoFmPGcHT",
    "outputId": "b8547a19-df65-4fda-b3a2-3c4eda9c33e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (33000, 2)\n",
      "Test data shape:  (5682, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", df_train.shape)\n",
    "print(\"Test data shape: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1648731194084,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "4Ixi7BU8IZot",
    "outputId": "d537be85-f201-4c27-b1fe-112aa6727ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (33000, 2)\n",
      "Columns are: Index(['lang_id', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Dataset size:',df_train.shape)\n",
    "print('Columns are:',df_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7uog88uKHj-"
   },
   "source": [
    "Looking at the number of languages and their frequencies in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1648731194085,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "rg-eQP2sKDuL",
    "outputId": "1ac2d55d-5aa5-4d23-ee0f-60f178e7eaed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xho    3000\n",
       "eng    3000\n",
       "nso    3000\n",
       "ven    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "tso    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce1GGYjQKZdg"
   },
   "source": [
    "The frequency of each of the eleven languages in the dataset is balanced. There are 3000 occurences of each language in the train dataset.\n",
    "It is pertinent to understand in real life it is natural to deal with imbalanced data in most cases. Therefore, the goal shoudld be on reducing imbalance to manageable levels. It will be interesting to assess the performance of the model when dealing with a balanced daa like the train dataset in this project. \n",
    "We can develop a bar chart to confirm the view of how each language occures through the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1648731194086,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "ZCTKLDigKTc_",
    "outputId": "ded2ba21-edcd-4234-c462-9fac76a7e41e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.lang_id.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VM-6BYQcNG_s"
   },
   "source": [
    "## 3. Data Preprocessing <a class=\"anchor\" id=\"Data_Preprocessing\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqj9kSvdOBkK"
   },
   "source": [
    "In preparation for modelling, it is important to ensure the dataset is turned into a formate that makes it easy for the model to make sense of the data. Text cleaning is necesary because it ensures that the text data is free of things like punctuation, numerical values and other signs that do not have a direct impact on the performance of the classification model. They are considered noise, which can ultimately affect the accuracy of the model. The key steps in text cleaning include:\n",
    "* Removal of special characters\n",
    "* Removing punctuation\n",
    "* Lowering the caps\n",
    "\n",
    "All these steps are carried to make it easy for machine learning models to make sense of the data during analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1648731194087,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "azX4QnOmN_t2"
   },
   "outputs": [],
   "source": [
    "# Create function to clean the data\n",
    "\n",
    "def text_cleaning(df, col):\n",
    "  \"\"\" Takes in a string value, returns string devoid of url, punctuation and caps lower\"\"\"\n",
    "\n",
    "  # Handling URLs\n",
    "  print ('Removing URLs...')\n",
    "  pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "  subs_url = r'url-web'\n",
    "  df[col] = df[col].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "\n",
    "  # Make lower case\n",
    "  print ('Lowering case...')\n",
    "  df[col] = df[col].str.lower()\n",
    "\n",
    "  # Dealing with Punctuation\n",
    "  print('Removing punctuation...')\n",
    "  def remove_punctuation_numbers(post):\n",
    "    punc_numbers = string.punctuation + '0123456789'\n",
    "    return ''.join([l for l in post if l not in punc_numbers])\n",
    "  df[col] = df[col].apply(remove_punctuation_numbers)\n",
    "  \n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1648731194088,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "lNVcEZQeLtlX"
   },
   "outputs": [],
   "source": [
    "# Create a copy of train and test data \n",
    "train_data = df_train.copy()\n",
    "test_data = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2675,
     "status": "ok",
     "timestamp": 1648731196749,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "MkxaUsoF1H-z",
    "outputId": "a6d5de99-4162-4500-c42e-4bc3d81213bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing URLs...\n",
      "Lowering case...\n",
      "Removing punctuation...\n",
      "Removing URLs...\n",
      "Lowering case...\n",
      "Removing punctuation...\n"
     ]
    }
   ],
   "source": [
    "# Apply Text Preprocessing\n",
    "train_data = text_cleaning(train_data, 'text')\n",
    "\n",
    "test_data = text_cleaning(test_data, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1648731196752,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "FOknzn4R1qkx",
    "outputId": "1ce19f47-87f9-4aac-f3c9-cef032afc7fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulunatal department of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqosiseko wenza amalungiselelo kumaziko axh...\n",
       "1     xho  idha iya kuba nobulumko bokubeka umsebenzi nap...\n",
       "2     eng  the province of kwazulunatal department of tra...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Cleaned Train Data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1648731196754,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "HtSFmVtw1wWQ",
    "outputId": "87c37b01-fa8a-4052-b128-f608d4fd4b19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mmasepala fa maemo a a kgethegileng a letlelel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  mmasepala fa maemo a a kgethegileng a letlelel...\n",
       "1      2  uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3          tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3      4  kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                       winste op buitelandse valuta"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Cleaned Test Data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjSFFfox6MjD"
   },
   "source": [
    "## 4. Feature Engineering <a class=\"anchor\" id=\"Feature_Engineering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3B82cRcS2WNb"
   },
   "source": [
    "### 4.1 Tfid Vectorizer <a class=\"anchor\" id=\"tfidvectorizer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHF-rvrN2dgz"
   },
   "source": [
    "[Term Frequency Inverse Document Frequency(TF-IDF)](https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558) is an algorithm that the frequency of word in a document and its rareness across the whole corpus of documents. Term Frequency(tf) is focused on how many times a word appears in a particular document Sklearn tf checks the number of times a term 'x' occurs in a document. \n",
    "Inverse Document Frequency(idf) measures how rare or common a term is the entire corpus of documents. A word that is frequent in all the documents analyzed has a normalisation approaching zero or 1 if it is not the case. Sklearn uses the formula:\n",
    "* idf(t) = log e [ (1+n) / ( 1 + df(t) ) ] + 1 (default i:e smooth_idf = True)\n",
    "\n",
    "    and\n",
    "\n",
    "* idf(t) = log e [ n / df(t) ] + 1 (when smooth_idf = False)\n",
    "\n",
    "The Term Frequency-Inverse Document Frequency(tf-idf) of a document is the product of tf and idf. A higher value indicates the term is more relevant in the document. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1648731196759,
     "user": {
      "displayName": "Kamire",
      "userId": "11293208691524921421"
     },
     "user_tz": -180
    },
    "id": "_f70akj62cRB"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1500, max_df=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCBaoXNK_-Ls"
   },
   "source": [
    "The next step is to fit all the words on the vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mfAxH8Pe_iQO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (33000, 1500)\n",
      "Test Data:  (5682, 1500)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize Train Data\n",
    "train_data_vec = vectorizer.fit_transform(train_data['text']).toarray()\n",
    "\n",
    "# Create dataframe for training data\n",
    "train_new = pd.DataFrame(train_data_vec, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Print shape of training dataframe\n",
    "print('Training Data: ', train_new.shape)\n",
    "\n",
    "# Vectorize test data\n",
    "test_data_vec = vectorizer.transform(test_data['text']).toarray()\n",
    "\n",
    "# New Dataframe for test data\n",
    "test_new = pd.DataFrame(test_data_vec, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Print the shape of test data\n",
    "print('Test Data: ', test_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Count Vectorizer  <a class=\"anchor\" id=\"countvectorizer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer converts words into numbers that show the frequency of the word in the document. The major difference between Count Vectorizer and TFIDVectorizer is that the former focuses on the count frequency of the word in the document while TFID goes ahead to consider how important a word is in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to prepare some train and test data vectorized using Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (33000, 1500)\n",
      "Test Data:  (5682, 1500)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize Train Data\n",
    "count_train = vectorizer.fit_transform(train_data['text']).toarray()\n",
    "\n",
    "# Create dataframe for training data\n",
    "count_train = pd.DataFrame(train_data_vec, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Print shape of training dataframe\n",
    "print('Training Data: ', train_new.shape)\n",
    "\n",
    "# Vectorize test data\n",
    "count_test = vectorizer.transform(test_data['text']).toarray()\n",
    "\n",
    "# New Dataframe for test data\n",
    "count_test = pd.DataFrame(test_data_vec, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Print the shape of test data\n",
    "print('Test Data: ', test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Prepare Data for Training <a class=\"anchor\" id=\"preparedatafortraining\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we define features(X) and target(Y) for training. Label Encoding is used to transform string language identities into numerical values for the model to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_new\n",
    "y = train_data['lang_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply label encoding in the next cell to convert them into numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder() \n",
    "y_label = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Data into train and test for data created using TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test and train data vectorized using Count Vectorizer for comparative purposes. The target value is the same for both vectorizing methods from scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y_label, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aan</th>\n",
       "      <th>aansoek</th>\n",
       "      <th>abantu</th>\n",
       "      <th>abantwana</th>\n",
       "      <th>abanye</th>\n",
       "      <th>abasebenzi</th>\n",
       "      <th>abe</th>\n",
       "      <th>abo</th>\n",
       "      <th>act</th>\n",
       "      <th>aforika</th>\n",
       "      <th>...</th>\n",
       "      <th>ḓa</th>\n",
       "      <th>ḓi</th>\n",
       "      <th>ḓo</th>\n",
       "      <th>ḓuvha</th>\n",
       "      <th>ḽa</th>\n",
       "      <th>ḽi</th>\n",
       "      <th>ḽo</th>\n",
       "      <th>ṅwaha</th>\n",
       "      <th>ṱhanziela</th>\n",
       "      <th>ṱo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aan  aansoek  abantu  abantwana  abanye  abasebenzi  abe  abo  act  \\\n",
       "0  0.0      0.0     0.0        0.0     0.0         0.0  0.0  0.0  0.0   \n",
       "1  0.0      0.0     0.0        0.0     0.0         0.0  0.0  0.0  0.0   \n",
       "2  0.0      0.0     0.0        0.0     0.0         0.0  0.0  0.0  0.0   \n",
       "3  0.0      0.0     0.0        0.0     0.0         0.0  0.0  0.0  0.0   \n",
       "4  0.0      0.0     0.0        0.0     0.0         0.0  0.0  0.0  0.0   \n",
       "\n",
       "   aforika  ...   ḓa   ḓi   ḓo  ḓuvha   ḽa   ḽi   ḽo  ṅwaha  ṱhanziela   ṱo  \n",
       "0      0.0  ...  0.0  0.0  0.0    0.0  0.0  0.0  0.0    0.0        0.0  0.0  \n",
       "1      0.0  ...  0.0  0.0  0.0    0.0  0.0  0.0  0.0    0.0        0.0  0.0  \n",
       "2      0.0  ...  0.0  0.0  0.0    0.0  0.0  0.0  0.0    0.0        0.0  0.0  \n",
       "3      0.0  ...  0.0  0.0  0.0    0.0  0.0  0.0  0.0    0.0        0.0  0.0  \n",
       "4      0.0  ...  0.0  0.0  0.0    0.0  0.0  0.0  0.0    0.0        0.0  0.0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling <a class=\"anchor\" id=\"Modelling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following models will be tried in this section with the hope selecting the best performing model:\n",
    "* Logistic Regression\n",
    "* Passive Aggressive Classifier\n",
    "* XGBoost Classifier\n",
    "* MultiNomialNB\n",
    "* GaussianNB\n",
    "* BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Build Classification Models <a class=\"anchor\" id=\"buildclassificationmodels\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modelling process is time intensive and demands a lot of computing power. In this section, I will use a limited number of features to assess the performance of pre-selected models before selecting one model for hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'MultiNomial', \n",
    "         'Passive', 'Gaussian',  'Bernoulli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(), \n",
    "    MultinomialNB(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    GaussianNB(),\n",
    "    BernoulliNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting MultiNomial model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Passive model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Gaussian model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Bernoulli model...\n",
      "... predicting\n",
      "... scoring\n",
      "... All done!\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "\n",
    "for name, clf in zip(names, classifiers):    \n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "    \n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)   \n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='macro')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='macro')\n",
    "    \n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='macro')    \n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='macro')    \n",
    "    \n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf    \n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "    \n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', \n",
    "                                         'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Train</th>\n",
       "      <th>F1 Test</th>\n",
       "      <th>Train Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>0.984747</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>0.984680</td>\n",
       "      <td>0.984636</td>\n",
       "      <td>0.977280</td>\n",
       "      <td>11.965616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.984074</td>\n",
       "      <td>0.983993</td>\n",
       "      <td>0.984004</td>\n",
       "      <td>0.983986</td>\n",
       "      <td>0.982695</td>\n",
       "      <td>31.022240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli</th>\n",
       "      <td>0.981852</td>\n",
       "      <td>0.981868</td>\n",
       "      <td>0.981775</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.984439</td>\n",
       "      <td>0.592999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiNomial</th>\n",
       "      <td>0.979461</td>\n",
       "      <td>0.979377</td>\n",
       "      <td>0.979366</td>\n",
       "      <td>0.979327</td>\n",
       "      <td>0.981940</td>\n",
       "      <td>0.208341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.964276</td>\n",
       "      <td>0.966294</td>\n",
       "      <td>0.964121</td>\n",
       "      <td>0.963036</td>\n",
       "      <td>0.962900</td>\n",
       "      <td>0.832703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1 Train   F1 Test  \\\n",
       "Classifier                                                               \n",
       "Passive              0.984747   0.984947  0.984680  0.984636  0.977280   \n",
       "Logistic Regression  0.984074   0.983993  0.984004  0.983986  0.982695   \n",
       "Bernoulli            0.981852   0.981868  0.981775  0.981749  0.984439   \n",
       "MultiNomial          0.979461   0.979377  0.979366  0.979327  0.981940   \n",
       "Gaussian             0.964276   0.966294  0.964121  0.963036  0.962900   \n",
       "\n",
       "                     Train Time  \n",
       "Classifier                       \n",
       "Passive               11.965616  \n",
       "Logistic Regression   31.022240  \n",
       "Bernoulli              0.592999  \n",
       "MultiNomial            0.208341  \n",
       "Gaussian               0.832703  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('F1 Train', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Classifier'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "results.sort_values('F1 Train', ascending=False, inplace=True)\n",
    "results.plot(y=['F1 Test'], kind='bar', ax=ax[0], xlim=[0,1.1], ylim=[0.85,0.92])\n",
    "results.plot(y='Train Time', kind='bar', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of all the five models is above 0.95, which is impressive. The analysis for was done using vectorized data with 1500 features. The best performing model is Passive Aggressive with a score of 0.98. I took time to delve deeper into all the models tested because of the high accuracy values during the test. The key difference among the models tested lies in the time it takes to train the model. \n",
    "\n",
    "Logistic Regression registered the highest time followed by Passive Aggressive Classifier. The low running times shown by Naive Bayes algorithms can be attributed to the simplicity in the way they deal with classification problems. The 'naive' assumption of independence among variables given the class one variable is determined means less time is spend on finding the smooth curves separating different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Logistic Regression <a class=\"anchor\" id=\"logisticregression\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a the process of  determining the probability of an outcome given an input. In this instance, I utilised the Logistic Regression algorithm from Sklearn Linear models. In machine learning, logisic regression algorithm is used in modelling the classification of categorical variables. It is applicable in text analysis that requires the determination of different categories of data based on language, which explains why it is selected for this task. The model is fitted and predicted on the validation data to check accuracy levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       0.99      1.00      1.00       272\n",
      "           2       0.98      0.98      0.98       312\n",
      "           3       1.00      1.00      1.00       277\n",
      "           4       1.00      1.00      1.00       299\n",
      "           5       0.99      0.99      0.99       320\n",
      "           6       1.00      1.00      1.00       295\n",
      "           7       1.00      1.00      1.00       299\n",
      "           8       1.00      1.00      1.00       306\n",
      "           9       0.98      0.97      0.98       308\n",
      "          10       0.95      0.96      0.96       312\n",
      "\n",
      "    accuracy                           0.99      3300\n",
      "   macro avg       0.99      0.99      0.99      3300\n",
      "weighted avg       0.99      0.99      0.99      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Passive Aggressive Classifier <a class=\"anchor\" id=\"logisticregression\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Passive Aggressive Classifier algorithm is known for its applications in online systems. The algorith reacts passively to correct classification and aggressively towards misclassification, which explains the name Passive Aggressive.  The suitability of the algorithm is derived from the tests performed above and level of performance shown when dealing with 1500 features in the train and validation data. In this section, I fit the model and predict using the split test data with the aim of checking the accuracy on the train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       300\n",
      "           1       0.99      1.00      1.00       272\n",
      "           2       0.99      0.96      0.98       312\n",
      "           3       1.00      1.00      1.00       277\n",
      "           4       1.00      1.00      1.00       299\n",
      "           5       0.97      0.99      0.98       320\n",
      "           6       1.00      1.00      1.00       295\n",
      "           7       1.00      1.00      1.00       299\n",
      "           8       1.00      1.00      1.00       306\n",
      "           9       0.96      0.97      0.96       308\n",
      "          10       0.96      0.93      0.94       312\n",
      "\n",
      "    accuracy                           0.99      3300\n",
      "   macro avg       0.99      0.99      0.99      3300\n",
      "weighted avg       0.99      0.99      0.99      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pa_clf = PassiveAggressiveClassifier(max_iter=50, n_jobs=-1)\n",
    "pa_clf.fit(X_train, y_train)\n",
    "pa_clf_pred = pa_clf.predict(X_test)\n",
    "print(classification_report(y_test, pa_clf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. XGBoost Classifier <a class=\"anchor\" id=\"xgboostclassifier\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is a popular algorithm known for its robust and powerful nature when it comes to machine learning problems. The motivation behind the selection is guided by extensive reading that testifies to the effectives of the XGBClassifier in handling text data. In this section, the model is fitted and predited using validation to check accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', verbosity='2', num_class=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train, y_train)\n",
    "xgb_pred = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 0.98 when using 1,500 features on the vectorizer.Overfitting is a possibility in this case. It might come clear when tested on the test dataset. The score on the leaderboard gave 0.76, which confirms that model is overfitting on the validation data. \n",
    "The biggest challenge with the application of XGBClassifier in this challenge is the demand for time and tuning needed to get a better performance. There are models like Passive Aggressive, Logistic Regression and Naive Bayes that have performed better with less tuning. I would recommend the application of XGBClassifier if one has an intimate understanding of the dataset, time is not a factor and access to adequate computing memory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Naive Bayes <a class=\"anchor\" id=\"naivebayes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes methods are founded on the principles of Bayes Theorem. The term 'naive' is the because of the assumption of indepence between every pair of features as long as the class of the variable is provided. \n",
    "* The Multinomial Naive Bayes Classifier is considered suitable for discrete features classification. It can work well with tf-idf fraction counts in some instances.\n",
    "* Gaussian Naive Bayes has the ability to update the parameters of the features using partial fit.\n",
    "* Bernoulli Naive Bayes is also good for discrete features. The key difference with Multinomial is that it works well with binary/boolean features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()\n",
    "GB = GaussianNB()\n",
    "BN = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       0.99      1.00      0.99       272\n",
      "           2       1.00      1.00      1.00       312\n",
      "           3       1.00      1.00      1.00       277\n",
      "           4       1.00      1.00      1.00       299\n",
      "           5       1.00      1.00      1.00       320\n",
      "           6       1.00      1.00      1.00       295\n",
      "           7       1.00      1.00      1.00       299\n",
      "           8       1.00      1.00      1.00       306\n",
      "           9       1.00      1.00      1.00       308\n",
      "          10       1.00      0.99      0.99       312\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB.fit(X_train, y_train)\n",
    "NB_pred= NB.predict(X_test)\n",
    "print(classification_report(y_test, NB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       0.99      1.00      1.00       272\n",
      "           2       1.00      1.00      1.00       312\n",
      "           3       1.00      1.00      1.00       277\n",
      "           4       1.00      1.00      1.00       299\n",
      "           5       1.00      1.00      1.00       320\n",
      "           6       1.00      1.00      1.00       295\n",
      "           7       1.00      1.00      1.00       299\n",
      "           8       1.00      1.00      1.00       306\n",
      "           9       1.00      1.00      1.00       308\n",
      "          10       1.00      0.99      1.00       312\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BN.fit(X_train, y_train)\n",
    "BN_pred= BN.predict(X_test)\n",
    "print(classification_report(y_test, BN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       1.00      1.00      1.00       272\n",
      "           2       0.99      0.98      0.98       312\n",
      "           3       0.98      1.00      0.99       277\n",
      "           4       0.99      0.99      0.99       299\n",
      "           5       1.00      1.00      1.00       320\n",
      "           6       1.00      0.99      0.99       295\n",
      "           7       1.00      1.00      1.00       299\n",
      "           8       1.00      1.00      1.00       306\n",
      "           9       0.98      0.99      0.99       308\n",
      "          10       0.98      0.97      0.98       312\n",
      "\n",
      "    accuracy                           0.99      3300\n",
      "   macro avg       0.99      0.99      0.99      3300\n",
      "weighted avg       0.99      0.99      0.99      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GB.fit(X_train, y_train)\n",
    "GB_pred= GB.predict(X_test)\n",
    "print(classification_report(y_test, GB_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes for data vectorized using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       0.99      1.00      0.99       272\n",
      "           2       1.00      1.00      1.00       312\n",
      "           3       1.00      1.00      1.00       277\n",
      "           4       1.00      1.00      1.00       299\n",
      "           5       1.00      1.00      1.00       320\n",
      "           6       1.00      1.00      1.00       295\n",
      "           7       1.00      1.00      1.00       299\n",
      "           8       1.00      1.00      1.00       306\n",
      "           9       1.00      1.00      1.00       308\n",
      "          10       1.00      0.99      1.00       312\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB.fit(X_train1, y_train1)\n",
    "NB_pred_count= NB.predict(X_test1)\n",
    "print(classification_report(y_test1, NB_pred_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes models generated the following outcomes on the leaderboad:\n",
    "* Multinomial Naive Bayes : Highest F1 Score with 0.96\n",
    "* Gaussian Naive Bayes : Second Highest F1 Score of 0.93\n",
    "* Bernoulli Naive Bayes : Third Highest with F1 Score of 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome for the validation data has the same accuracy as the data vectorized using TfidVectorizer. The score on the leaderboard is exactly the same as the one scored using TfidVectorizer, which suggests in this particular language identification the two vectorizers with minimal tuning have the same effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting the model with the unseen data (the test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pred = BN.predict(test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Submission  <a class=\"anchor\" id=\"submission\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesubmission.head()\n",
    "submission = pd.DataFrame()\n",
    "submission['index'] = test_data['index']\n",
    "submission['lang_id'] = label_encoder.inverse_transform(sub_pred)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion  <a class=\"anchor\" id=\"Conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the all the models tried on the provided dataset are as follows:\n",
    "* Logistic Regression - F1 Score 0.87\n",
    "* Passive Aggressive Classifer - F1 Score 0.92\n",
    "* XGBClassifier - F1 Score 0.75\n",
    "* Multinomial NB - F1 Score 0.96\n",
    "* Gaussian NB - F1 Score 0.93\n",
    "* Bernoulli NB - F1 Score o,89\n",
    "\n",
    "From the list, the best performing model is Multinomial NB that uses the principles from Bayes Theorem to classify discrete data. It should noted that hyperparameter tuning for Logistic Regression, Passive Aggressive and XGBoost can lead to significant changes as witnessed in other NLP machine learning challenges. In this cases, there was a limit of time and computing power that made it a challenge to delve deep into tuning parameters for all the models. The Naive Bayes algorithms did very well with minimal tuning, which leads to the conclusion that are the best for classification of text data. The application of Naive Bayes in recommender system is a testament of its prowess in text data classifiction. \n",
    "\n",
    "The most challenging aspect in all the models is the limit of memory when I tried using all the features from the vectorizer. The performance of MultinomialNB improved steadly with increase in the number of features before hitting a plateau at around 50000 features. Computing power is massively affected hardware that can make it difficult to check the full range of some models. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCZjGvj9uUElUxPwaZm/Cr",
   "name": "Language_Identification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
